<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Om Kathalkar </title> <meta name="author" content="Om Kathalkar"> <meta name="description" content="AI researcher working on camera-based AQI estimation, deep learning, autonomous mobile robots, and network-aware path planning. MS by Research from IIIT Hyderabad. "> <meta name="keywords" content="Om Kathalkar, Air Quality Estimation, Camera-based AQI, Computer Vision, Deep Learning, 360-degree Images, Environmental AI, Autonomous Mobile Robots, Network-Aware Path Planning, 5G Simulation, Sionna, Smart City Living Lab, IIIT Hyderabad, Multi-View Learning, Machine Learning Researcher, Urban Computing, NTUA PhD"> <meta charset="utf-8"> <meta name="google-site-verification" content="4VjMb9HZKB5nNLeZtpAYXzuhzQbQDKvL75vHjU1em34"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%91%F0%9F%8F%BB%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://omkathalkar.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Om Kathalkar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item dropdown active"> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus <span class="sr-only">(current)</span> </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item active" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2026</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Springer Nature</abbr> </div> <div id="Kathalkar2026network_aware" class="col-sm-8"> <div class="title">Network-aware path planning for AMRs: A generalizable framework with spatial-aware adaptation</div> <div class="author"> Om Kathalkar, Houssam Hajj Hassan, Ajay Kattepur, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Georgios Bouloukakis' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Springer Nature Autonomous Robots</em>, Jan 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/-" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Industrial autonomous mobile robots increasingly depend on reliable wireless connectivity for real-time control and data streaming, yet existing path planning methods fail to account for the complex interplay between spatial geometries and material-dependent signal propagation across heterogeneous facility environments. This paper presents a spatial-aware transformer framework for network quality prediction that explicitly encodes both geometric layouts and electromagnetic properties (permittivity, conductivity, reflection coefficients, absorption coefficients) of building materials to enable accurate signal strength, throughput, and latency predictions across diverse industrial facilities. The framework represents environments through declarative YAML specifications capturing wall geometry and validated ITU-R material properties, eliminating exhaustive physical site surveys. Rigorous validation against the iV2I+ real-world measurement dataset established Sionna ray-tracing simulation fidelity with R2 = 0.87 for SNR predictions, providing confidence in physics-based ground truth for supervised learning. Comprehensive evaluation across 8,840 test paths spanning concrete, wood, and metal environments with varying geometric configurations demonstrated SNR prediction RMSE of 2.31 dB with R2 = 0.891, representing 19.5% improvement over state-of-the-art baselines. Critically, zero-shot evaluation on mixed-material scenarios and held-out geometric layouts—combining spatial and material configurations never jointly observed during training— yielded only 10% performance degradation, eliminating facility-specific retraining requirements. Ablation studies confirmed spatial-material encoding’s essential contribution with 47% accuracy improvement over encoding-agnostic variants, while computational efficiency analysis revealed 73 ms inference time achieving 31× speedup compared to graph neural network baselines. The framework enables train-once-deploy-everywhere paradigm for industrial system integrators, with single trained models serving warehouses, manufacturing floors, and assembly areas without site-specific customization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Kathalkar2026network_aware</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Network-aware path planning for AMRs: A generalizable framework with spatial-aware adaptation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{{Om Kathalkar} and Hassan, Houssam Hajj and Kattepur, Ajay and Bouloukakis, Georgios}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer Nature}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Springer Nature Autonomous Robots}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{-}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IEEE ANTS 2025</abbr> </div> <div id="Kathalkar2025network_aware" class="col-sm-8"> <div class="title">Network-Aware Path Planning for Autonomous Mobile Robots in Industrial Environments</div> <div class="author"> Om Kathalkar, Houssam Hajj Hassan, Ajay Kattepur, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Georgios Bouloukakis' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>IEEE International Conference on Advanced Networks and Telecommunications Systems, India</em>, Oct 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/-" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://omkathalkar.github.io/networkaware/" class="btn btn-sm z-depth-0" role="button">HTML</a> </div> <div class="abstract hidden"> <p>Autonomous Mobile Robots (AMRs) in industrial environments require reliable wireless connectivity for coordination, control, and safety operations. Traditional path planning algorithms focus solely on geometric constraints, often leading robots through areas with poor network coverage that can compromise mission-critical operations. This paper presents a comprehensive framework for network-aware path planning that incorporates wireless network quality metrics as path constraints. We validate our Sionna-based ray-tracing simulations against real-world measurements from the Hernangomez et al. iV2I+ dataset, achieving strong correlation between simulated and real-world measurements (R² = 0.87 for SNR, 0.82 for throughput). Using this validated simulation framework, we implement three novel path planning algorithms: A* with network constraints, conditional variational autoencoder (CVAE)-based neural path planning, and Graph neural network-based multi-path (GraphMP) planning. Our evaluation demonstrates trade-offs between network quality requirements and path efficiency, with CVAE achieving 95.2% constraint satisfaction and GraphMP showing 23% shorter planning times. We provide practical guidelines for selecting appropriate algorithms and network quality thresholds based on application requirements, enabling more reliable AMR operations in industrial settings.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Kathalkar2025network_aware</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Network-Aware Path Planning for Autonomous Mobile Robots in Industrial Environments}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{{Om Kathalkar} and Hassan, Houssam Hajj and Kattepur, Ajay and Bouloukakis, Georgios}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Advanced Networks and Telecommunications Systems, India}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{-}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICVGIP 2025</abbr> </div> <div id="Kathalkar2025AQIFormer" class="col-sm-8"> <div class="title">AQIFormer: A Transformer-Based Multi-View Architecture for Cross-City Air Quality Classification</div> <div class="author"> Om Kathalkar, Nitin Nilesh, Sachin Chaudhari, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Anoop Namboodiri' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>16th Indian Conference on Computer Vision Graphics and Image Processing, Mandi, India</em>, Oct 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3774521.3774577" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://omkathalkar.github.io/aqiformer/" class="btn btn-sm z-depth-0" role="button">HTML</a> <a href="https://github.com/omkathalkar/AQIFormer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Air pollution represents one of the most critical environmental and public health challenges globally, with traditional sensor-based monitoring systems facing significant scalability and economic constraints. Image-based air quality estimation has emerged as a promising alternative, leveraging the visual characteristics of atmospheric pollutants in traffic scenes. However, existing methods suffer from limited cross-city generalization and inadequate exploitation of multi-view perspectives. We present AQIFormer, a novel transformer-based ensemble architecture that addresses these fundamental limitations through innovative dual-view integration, weather-aware attention mechanisms, and comprehensive multi-task learning. Our approach uniquely combines front and rear traffic imagery with meteorological parameters to achieve robust air quality classification across diverse urban environments. Extensive evaluation on a dataset of 26,678 synchronized front–rear image pairs demonstrates 89.96% accuracy, representing a 14.96% improvement over state-of-the-art methods. Most importantly, our model maintains exceptional cross-city generalization capabilities, achieving 81.67% accuracy on an independent dataset collected in Nagpur, India, with only 8.29% performance degradation using few-shot adaptation and minimal training samples.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Kathalkar2025AQIFormer</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{AQIFormer: A Transformer-Based Multi-View Architecture for Cross-City Air Quality Classification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{{Om Kathalkar} and Nilesh, Nitin and Chaudhari, Sachin and Namboodiri, Anoop}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{16th Indian Conference on Computer Vision Graphics and Image Processing, Mandi, India}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3774521.3774577}</span><span class="p">,</span>
  <span class="na">dataset</span> <span class="p">=</span> <span class="s">{https://india-data.org/dataset-details/4965db32-3676-427f-86f0-c8ed678dad2b}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Patent</abbr> </div> <div id="202541073518" class="col-sm-8"> <div class="title">202541073518 - System for Determining Air Quality Index (AQI) in Urban Environments</div> <div class="author"> Om Kathalkar, Ansh Shah, Sachin Chaudhari, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Anoop Namboodiri' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Indian Patent Office</em>, Jul 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://iprsearch.ipindia.gov.in/PublicSearch/PublicationSearch/ApplicationStatus" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>A system 100 for accurately determining Air Quality Index (AQI) in urban environments exhibiting high spatial and temporal variability is disclosed. The system includes a mobile platform 102 equipped with a multi-camera data acquisition system 108 and an array of environmental sensors 104. The multi-camera data acquisition system 108 includes front-facing camera 110, rear-facing camera 112, and 360-degree camera 114 configured to capture real-time environmental imagery. The environmental sensors 104 include particulate matter (PM2.5 and PM10) sensors 116, noise sensors 118, and contextual sensors 120 for collecting weather and temporal data. An edge computing device 106, operatively connected to the cameras and sensors, processes the acquired data using deep learning-based feature extraction pipelines 126. The system performs visual and contextual feature fusion through cross-view alignment and modality concatenation, followed by encoding with a transformer-based encoder 128 incorporating multi-head attention.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Patent</abbr> </div> <div id="202441043706" class="col-sm-8"> <div class="title">202441043706 - System and Method for Determining Air Quality by Processing Environmental and Traffic-Related Visual Data</div> <div class="author"> Om Kathalkar, Nitin Nilesh, Sachin Chaudhari, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Anoop Namboodiri' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Indian Patent Office</em>, Jun 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://iprsearch.ipindia.gov.in/PublicSearch/PublicationSearch/ApplicationStatus" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>A system 100 and method are disclosed for automated air quality determination using multimodal data fusion and a transformer-based deep learning architecture. The system (100) receives synchronized video streams from a first camera (104) and a second camera (106) along with environmental sensor data from an air quality monitoring device (108). Images are sampled at defined intervals, annotated with sensor data and contextual metadata, and processed using a frozen convolutional neural network to extract feature vectors. These visual features are combined with standardized sensor readings and encoded contextual information to form a unified feature representation. A custom transformer model projects this representation into a token sequence with positional encoding. The final classification is performed using the transformer’s last token output, which captures attention-weighted spatial-temporal correlations between visual indicators and environmental factors. The system outputs a six-category air quality index (AQI) classification, including good, satisfactory, moderate, poor, very poor, or severe.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICVGIP 2024</abbr> </div> <div id="Kathalkar2024TRAQID" class="col-sm-8"> <div class="title">TRAQID - Traffic-Related Air Quality Image Dataset</div> <div class="author"> Om Kathalkar, Nitin Nilesh, Sachin Chaudhari, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Anoop Namboodiri' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>15th Indian Conference on Computer Vision Graphics and Image Processing, Bengaluru, India</em>, Oct 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3702250.3702260" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://omkathalkar.github.io/traqid/" class="btn btn-sm z-depth-0" role="button">HTML</a> <a href="/assets/pdf/icvgip2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/omkathalkar/TRAQID-Traffic-Related-Air-Quality-Image-Dataset" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://docs.google.com/presentation/d/1tt2Ssz_DXKnbBAy3NtKf4p1CpG4xGKjAXJQqDhz-pYg/edit#slide=id.p" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> </div> <div class="abstract hidden"> <p>Air quality estimation through sensor-based methods is widely used. Nevertheless, their frequent failures and maintenance challenges constrain the scalability of air pollution monitoring efforts. Recently, it has been demonstrated that air quality estimation can be done using image-based methods. These methods offer several advantages including ease of use, scalability, and low cost. However, the accuracy of these methods hinges significantly on the diversity and magnitude of the dataset utilized. The advancement of air quality estimation through image analysis has been limited due to the lack of available datasets. Addressing this gap, we present TRAQID - Traffic-Related Air Quality Image Dataset, a novel dataset capturing 26,678 front and rear images of traffic alongside co-located weather parameters, multiple levels of Particulate Matters (PM) and Air Quality Index (AQI) values. Spanning over multiple seasons, with over 70 hours of data collection in the twin cities of Hyderabad and Secunderabad, India, the TRAQID offers diverse day and night imagery amid unstructured traffic conditions, encompassing six AQI categories ranging from “Good” to “Severe”. State-of-the-art air quality estimation techniques, which were trained on a smaller and less-diverse dataset, showed poor results on the dataset presented in this paper. TRAQID models various uncertainty types, including seasonal changes, unstructured traffic patterns, and lighting conditions. The information from the two views (front and rear) of the traffic can be combined to improve the estimation performance in such challenging conditions. As such, the TRAQID serves as a benchmark for image-based air quality estimation tasks and AQI prediction, given its diversity and magnitude.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Kathalkar2024TRAQID</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TRAQID - Traffic-Related Air Quality Image Dataset}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{{Om Kathalkar} and Nilesh, Nitin and Chaudhari, Sachin and Namboodiri, Anoop}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{15th Indian Conference on Computer Vision Graphics and Image Processing, Bengaluru, India}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3702250.3702260}</span><span class="p">,</span>
  <span class="na">dataset</span> <span class="p">=</span> <span class="s">{https://india-data.org/dataset-details/4965db32-3676-427f-86f0-c8ed678dad2b}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Patent</abbr> </div> <div id="patentvision" class="col-sm-8"> <div class="title">System and Method for Implementing an Experiment Remotely and Determining an Output Using a Computer Vision Model</div> <div class="author"> Sachin Chaudhari,  Om Rajendra Kathalkar, Viswanadh Savita Kandala, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Nitin Nilesh' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>United States Patent and Trademark Office</em>, Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://patentcenter.uspto.gov/applications/18241852" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>A system and method for implementing an experiment remotely and determining an output using a computer-vision model is provided. The system includes an image capturing device, an experiment setup, a microcontroller, a user device, and a relay unit. The microcontroller (i) receives the input of the experiment from the image capturing device, (ii) extracts one or more frames from the input data, (iii) pre-process the one or more frames to obtain a binary image, (iv) obtain a closed curve around the binary image to locate the experiment, (v) determine the coordinates of the experiment to track the experiment in each frame, (vi) determine an output of the experiment from every two consecutive frames of the one or more frames, and (vii) optimize the determined output of the experiment using a linear regression model.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EnvSys 2023</abbr> </div> <div id="hunting_PM25_hot_spots" class="col-sm-8"> <div class="title">Protocol for hunting PM2.5 emission hot spots in cities</div> <div class="author"> Sara Spanddhana, Andrew Rebeiro-Hargrave,  Om Kathalkar, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Samu Varjonen, Sachin Chaudhari, Sasu Tarkoma' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Proceedings of the 1st International Workshop on Advances in Environmental Sensing Systems for Smart Cities</em>, Mar 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3597064.3597322" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://researchportal.helsinki.fi/en/publications/protocol-for-hunting-pmsub25subemission-hot-spots-in-cities" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Particulate Matter (PM) is a major air pollutant that has the potential for adversely affecting human health. Actionable data on the spatial distribution of temporal variability of PM2.5 emission hot spots in large cities are sparse. The main objective of this research is to provide a protocol for using search agents to hunt for PM2.5 emission hot spots in urban environments. We propose short-range identification of variability of harmful PM2.5 concentrations can be achieved using IoT devices mounted on a mobile platform. We propose that long-range identification of the PM2.5 emission hot spots can be attained by searching through the city on different days. We applied this approach to Hyderabad, India by fixing a mobile platform on a street car. We corrected the IoT device measurement errors by calibrating the sensing component data against a reference instrument co-located on the mobile platform. We identified that random forest regression was the most suitable technique to reduce the variability between the IoT devices. The spatial variability of PM2.5 harmful emission hot spots at industrial settings and congested roads were identified. The temporal variability based on image processing shows a weak correlation between PM2.5 concentrations and the number of vehicles, and PM2.5 and visibility. The Hyderabad PM2.5 emission hot spots findings demonstrate a clear need to inform people with heart and lung conditions when it is unhealthy to be outside, and when it is unhealthy for children and elderly people to be outside for prolonged periods. Our emission hunting approach can be applied to any mobile platform carried by people walking, cycling, or by drones and robots in any city.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hunting_PM25_hot_spots</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Protocol for hunting PM2.5 emission hot spots in cities}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Spanddhana, Sara and Rebeiro-Hargrave, Andrew and {Om Kathalkar} and Varjonen, Samu and Chaudhari, Sachin and Tarkoma, Sasu}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the 1st International Workshop on Advances in Environmental Sensing Systems for Smart Cities}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3597064.3597322}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3597064.3597322}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">FiCloud 2022</abbr> </div> <div id="ficloud2022" class="col-sm-8"> <div class="title">CV and IoT-based Remote Triggered Labs: Use Case of Conservation of Mechanical Energy</div> <div class="author"> K. S. Viswanadh,  Om Kathalkar, Nitin Nilesh, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Sachin Chaudhari, Venkatesh Choppella' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>9th International Conference on Future Internet of Things and Cloud (FiCloud), Rome, Italy</em>, Mar 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/FiCloud57274.2022.00021" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9910543" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/ficloud2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Remote Triggered Labs (RTL) are helpful for students to work on laboratory experiments virtually anytime, anywhere. Such setups can facilitate distance learning and are helpful during pandemics. In this paper, the use of Computer Vision (CV) is demonstrated for RTL experiments. For this, a use-case of the Conservation of Mechanical Energy experiment is considered. A CV-based approach is used to estimate an object’s velocity whose setup primarily consists of a microprocessor, a camera and infrared (IR) sensors. The experiment is recorded, and various CV techniques are employed to estimate the object’s velocity. This paper also compares a CV-based and an IR sensor-based approach to estimate the object’s velocity. Linear regression applied to the CV-based implementation resulted in an optimal mean-squared error (MSE), nearly 10 times better than IR-based implementation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ficloud2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CV and IoT-based Remote Triggered Labs: Use Case of Conservation of Mechanical Energy}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Viswanadh, K. S. and {Om Kathalkar} and Nilesh, Nitin and Chaudhari, Sachin and Choppella, Venkatesh}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{9th International Conference on Future Internet of Things and Cloud (FiCloud), Rome, Italy}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/FiCloud57274.2022.00021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Om Kathalkar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-teaching",title:"teaching",description:"",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"dropdown-publications",title:"publications",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-projects",title:"projects",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-blog",title:"blog",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"news-awarded-ihub-data-fellowship-for-ms-research-and-studies",title:"Awarded iHub-Data Fellowship for MS research and studies \ud83c\udf93",description:"",section:"News"},{id:"news-our-patent-named-system-and-method-for-implementing-an-experiment-remotely-and-determining-an-output-using-a-computer-vision-model-accepted-for-publication-at-united-states-patent-and-trademark-office",title:"Our patent named System and Method for Implementing an Experiment Remotely and Determining...",description:"",section:"News"},{id:"news-joined-nse-talentsprint-as-a-mentor",title:"Joined NSE TalentSprint as a Mentor!\ud83d\udc68\u200d\ud83c\udfeb",description:"",section:"News"},{id:"news-thrilled-to-announce-that-my-paper-traqid-traffic-related-air-quality-image-dataset-is-accepted-at-indian-conference-on-computer-vision-graphics-and-image-processing-icvgip-2024-i-ll-present-it-as-a-spotlight-presentation-at-iiit-bangalore",title:"Thrilled to announce that my paper, \u201cTRAQID - Traffic-Related Air Quality Image Dataset,\u201d...",description:"",section:"News"},{id:"news-joined-ericsson-research-as-a-researcher",title:"Joined Ericsson Research as a Researcher!\ud83e\udd73",description:"",section:"News"},{id:"news-just-submitted-two-research-papers-\ufe0f-one-to-icvgip-2025-iit-mandi-and-another-to-ieee-ants-2025-delhi",title:"Just submitted two research papers \u270d\ufe0f \u2014 one to ICVGIP 2025, IIT Mandi,...",description:"",section:"News"},{id:"news-excited-to-share-that-i-have-submitted-my-ms-thesis-titled-camera-based-deep-learning-framework-for-aqi-estimation-dataset-and-methodology",title:"Excited to share that I have submitted my MS thesis titled: \u201cCamera-Based Deep...",description:"",section:"News"},{id:"news-delighted-to-share-that-my-paper-aqiformer-a-transformer-based-multi-view-architecture-for-cross-city-air-quality-classification-has-been-accepted-at-the-indian-conference-on-computer-vision-graphics-and-image-processing-icvgip-2025",title:"Delighted to share that my paper, \u201cAQIFormer: A Transformer-Based Multi-View Architecture for Cross-City...",description:"",section:"News"},{id:"news-honoured-to-share-that-my-paper-network-aware-path-planning-for-autonomous-mobile-robots-in-industrial-environments-has-been-accepted-at-the-ieee-international-conference-on-advanced-networks-and-telecommunications-systems-ants",title:"Honoured to share that my paper, \u201cNetwork-Aware Path Planning for Autonomous Mobile Robots...",description:"",section:"News"},{id:"news-successfully-defended-my-ms-by-research-thesis-titled-camera-based-deep-learning-framework-for-aqi-estimation-dataset-and-methodology-at-iiit-hyderabad",title:"Successfully defended my MS by Research thesis titled \u201cCamera-Based Deep Learning Framework for...",description:"",section:"News"},{id:"news-joined-national-technical-university-of-athens-ntua-greece-as-a-doctoral-researcher-working-with-the-institute-of-communication-and-computer-systems-iccs-under-the-horizon-europe-turing-project",title:"Joined National Technical University of Athens (NTUA), Greece as a Doctoral Researcher, working...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6F%6D.%6B%61%74%68%61%6C%6B%61%72@%72%65%73%65%61%72%63%68.%69%69%69%74.%61%63.%69%6E","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0009-0007-0884-715X","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=a_lzSPoAAAAJ","_blank")}},{id:"socials-ieee-xplore",title:"IEEE Xplore",section:"Socials",handler:()=>{window.open("https://ieeexplore.ieee.org/author/https://ieeexplore.ieee.org/author/37089580264/","_blank")}},{id:"socials-acm-dl",title:"ACM DL",section:"Socials",handler:()=>{window.open("https://dl.acm.org/profile/https://dl.acm.org/profile/99660920796/","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/om-kathalkar","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>